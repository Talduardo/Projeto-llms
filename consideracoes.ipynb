{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f417d05d",
   "metadata": {},
   "source": [
    "## Definindo os objetivos específicos da análise:\n",
    "\n",
    "- Analisar os dados úteis;\n",
    "- Tratar os dados;\n",
    "- Descartar os dados inúteis para análise;\n",
    "- Criar resumos, nos quais digam as ideias principais do arquivo e suas palavra chaves;\n",
    "- Teste da eficácia do programa/códigos;\n",
    "- Fazer as mudanças necessárias para melhor eficiência.\n",
    "\n",
    "## Objetivos dos códigos: \n",
    "\n",
    "- Criar uma função que visualize e identifique apenas os dados úteis para fazer resumos contábeis utilizando modelos de linguagens;\n",
    "\n",
    "- Criar uma função que descarte os arquivos inúteis e notifique isso;\n",
    "\n",
    "- Criar resumos claros e completos dos dados de fácil visualização;\n",
    "\n",
    "- Fazer testes para verificar a eficiência dos resumos, para poder melhorar ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "# Tentar baixar stopwords se não estiverem presentes\n",
    "try:\n",
    "    stopwords.words('portuguese')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    word_tokenize(\"exemplo\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Carregar o modelo de linguagem para spaCy\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading pt_core_news_sm language model for spaCy...\")\n",
    "    spacy.cli.download(\"pt_core_news_sm\")\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def identificar_dados_uteis_contabeis(\n",
    "    df: pd.DataFrame, colunas_texto: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Visualiza e identifica dados úteis para resumos contábeis em um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contendo os dados contábeis.\n",
    "        colunas_texto (List[str], optional): Lista de colunas que contêm texto para análise.\n",
    "                                         Se None, todas as colunas string/object serão consideradas.\n",
    "                                         Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com informações sobre a utilidade de cada coluna.\n",
    "    \"\"\"\n",
    "    info_utilidade = {}\n",
    "    for col in df.columns:\n",
    "        info = {\"tipo\": str(df[col].dtype), \"n_na\": df[col].isna().sum(), \"n_unique\": df[col].nunique()}\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            info[\"utilidade\"] = \"Potencialmente útil (numérico)\"\n",
    "            info[\"exemplos\"] = df[col].dropna().head().to_list()\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            info[\"utilidade\"] = \"Potencialmente útil (data)\"\n",
    "            info[\"exemplos\"] = df[col].dropna().head().to_list()\n",
    "        elif pd.api.types.is_string_dtype(df[col]) or df[col].dtype == \"object\":\n",
    "            info[\"exemplos\"] = df[col].dropna().astype(str).head().to_list()\n",
    "            if colunas_texto is None or col in colunas_texto:\n",
    "                textos = \" \".join(df[col].dropna().astype(str).head(100).tolist())\n",
    "                doc = nlp(textos)\n",
    "                entidades = [ent.text for ent in doc.ents]\n",
    "                palavras_chave = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "                if entidades or any(\n",
    "                    palavra in [\"R$\", \"USD\", \"valor\", \"total\", \"conta\", \"débito\", \"crédito\", \"imposto\", \"data\", \"ano\"]\n",
    "                ):\n",
    "                    info[\"utilidade\"] = \"Altamente útil (texto contábil)\"\n",
    "                elif info[\"n_unique\"] / len(df) > 0.8:\n",
    "                    info[\"utilidade\"] = \"Baixa utilidade (alta cardinalidade)\"\n",
    "                elif len(set(palavras_chave)) < 5:\n",
    "                    info[\"utilidade\"] = \"Baixa utilidade (pouca informação textual)\"\n",
    "                else:\n",
    "                    info[\"utilidade\"] = \"Potencialmente útil (texto)\"\n",
    "            else:\n",
    "                info[\"utilidade\"] = \"Não especificado para análise de texto\"\n",
    "        else:\n",
    "            info[\"utilidade\"] = \"Outro tipo\"\n",
    "            info[\"exemplos\"] = df[col].dropna().head().to_list()\n",
    "\n",
    "        info_utilidade[col] = info\n",
    "\n",
    "    return pd.DataFrame.from_dict(info_utilidade, orient=\"index\")\n",
    "\n",
    "\n",
    "def descartar_arquivos_inuteis(\n",
    "    lista_arquivos: List[str], palavras_chave_uteis: Optional[List[str]] = None\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Descartar arquivos considerados inúteis com base em seus nomes e notifica isso.\n",
    "\n",
    "    Args:\n",
    "        lista_arquivos (List[str]): Lista de nomes de arquivos a serem avaliados.\n",
    "        palavras_chave_uteis (List[str], optional): Lista de palavras-chave que indicam\n",
    "                                                    que um arquivo pode ser útil. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Lista de arquivos considerados úteis.\n",
    "    \"\"\"\n",
    "    arquivos_uteis = []\n",
    "    arquivos_descartados = []\n",
    "\n",
    "    if palavras_chave_uteis is None:\n",
    "        palavras_chave_uteis = [\n",
    "            \"contabil\",\n",
    "            \"financeiro\",\n",
    "            \"balanco\",\n",
    "            \"dre\",\n",
    "            \"fluxo\",\n",
    "            \"caixa\",\n",
    "            \"fiscal\",\n",
    "            \"imposto\",\n",
    "        ]\n",
    "\n",
    "    for arquivo in lista_arquivos:\n",
    "        nome_lower = arquivo.lower()\n",
    "        if any(keyword in nome_lower for keyword in palavras_chave_uteis):\n",
    "            arquivos_uteis.append(arquivo)\n",
    "        else:\n",
    "            arquivos_descartados.append(arquivo)\n",
    "\n",
    "    if arquivos_descartados:\n",
    "        print(\n",
    "            \"Os seguintes arquivos foram considerados inúteis e descartados: \"\n",
    "            f\"{', '.join(arquivos_descartados)}\"\n",
    "        )\n",
    "\n",
    "    return arquivos_uteis\n",
    "\n",
    "\n",
    "def criar_resumos_claros(df: pd.DataFrame, colunas_resumo: List[str], num_sentencas: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Cria resumos claros e completos dos dados de fácil visualização.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contendo os dados a serem resumidos.\n",
    "        colunas_resumo (List[str]): Lista de colunas de texto a serem usadas para o resumo.\n",
    "        num_sentencas (int, optional): Número de sentenças desejado no resumo. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        str: Resumo dos dados.\n",
    "    \"\"\"\n",
    "    textos_combinados = \"\"\n",
    "    for col in colunas_resumo:\n",
    "        if col in df.columns and (\n",
    "            pd.api.types.is_string_dtype(df[col]) or df[col].dtype == \"object\"\n",
    "        ):\n",
    "            textos_combinados += \" \".join(df[col].dropna().astype(str).tolist()) + \" \"\n",
    "\n",
    "    if not textos_combinados.strip():\n",
    "        return \"Nenhum texto relevante encontrado para gerar o resumo.\"\n",
    "\n",
    "    # Pré-processamento básico\n",
    "    textos_combinados = textos_combinados.lower()\n",
    "    tokens = word_tokenize(textos_combinados)\n",
    "    stop_words = set(stopwords.words(\"portuguese\"))\n",
    "    tokens_filtrados = [w for w in tokens if not w in stop_words and w.isalnum()]\n",
    "    texto_processado = \" \".join(tokens_filtrados)\n",
    "\n",
    "    # Vetorização TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([texto_processado])\n",
    "\n",
    "    # Calcular a importância das sentenças (simples, baseado na frequência de termos)\n",
    "    sentencas = nltk.sent_tokenize(textos_combinados)\n",
    "    if not sentencas:\n",
    "        return \"Não foram encontradas sentenças para resumir.\"\n",
    "\n",
    "    sentenca_pontuacao = {}\n",
    "    for i, sentenca in enumerate(sentencas):\n",
    "        tokens_sentenca = [word.lower() for word in word_tokenize(sentenca) if word.isalnum()]\n",
    "        pontuacao = 0\n",
    "        for token in tokens_sentenca:\n",
    "            if token in vectorizer.vocabulary_:\n",
    "                indice = vectorizer.vocabulary_[token]\n",
    "                pontuacao += tfidf_matrix[0, indice]\n",
    "        sentenca_pontuacao[i] = pontuacao\n",
    "\n",
    "    # Selecionar as melhores sentenças para o resumo\n",
    "    melhores_sentencas_indices = sorted(\n",
    "        sentenca_pontuacao, key=sentenca_pontuacao.get, reverse=True\n",
    "    )[:num_sentencas]\n",
    "    melhores_sentencas_indices.sort()  # Manter a ordem original\n",
    "\n",
    "    resumo = \" \".join([sentencas[i] for i in melhores_sentencas_indices])\n",
    "    return f\"**Resumo Contábil:**\\n\\n{resumo}\"\n",
    "\n",
    "\n",
    "def testar_eficiencia_resumo(resumo_gerado: str, resumo_esperado: str) -> float:\n",
    "    \"\"\"\n",
    "    Realiza um teste simples para verificar a eficiência do resumo gerado.\n",
    "    Utiliza similaridade de cossenos entre as representações TF-IDF dos resumos.\n",
    "\n",
    "    Args:\n",
    "        resumo_gerado (str): O resumo gerado pela função.\n",
    "        resumo_esperado (str): Um resumo de referência (feito por um humano, por exemplo).\n",
    "\n",
    "    Returns:\n",
    "        float: Uma pontuação de similaridade (entre 0 e 1), onde 1 indica alta similaridade.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([resumo_gerado, resumo_esperado])\n",
    "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "def extrair_dados_relevantes(\n",
    "    df: pd.DataFrame, colunas_relevantes: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrai apenas as colunas relevantes de um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "        colunas_relevantes (List[str]): Lista de nomes de colunas a serem extraídas.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Novo DataFrame contendo apenas as colunas relevantes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_relevante = df[colunas_relevantes].copy()  # Use .copy() para evitar warnings\n",
    "        return df_relevante\n",
    "    except KeyError as e:\n",
    "        print(f\"Erro: Coluna não encontrada - {e}\")\n",
    "        return pd.DataFrame()  # Retorna um DataFrame vazio em caso de erro\n",
    "\n",
    "\n",
    "def tratar_valores_ausentes(\n",
    "    df: pd.DataFrame, estrategia: str = \"preencher_zero\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trata valores ausentes em um DataFrame usando uma estratégia especificada.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame com valores ausentes.\n",
    "        estrategia (str, optional): Estratégia para tratar valores ausentes.\n",
    "            Opções: 'preencher_zero', 'remover_linhas', 'media', 'mediana'.\n",
    "            Defaults to 'preencher_zero'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com valores ausentes tratados.\n",
    "    \"\"\"\n",
    "    df_tratado = df.copy()  # Cria uma cópia para não modificar o DataFrame original diretamente\n",
    "    if estrategia == \"preencher_zero\":\n",
    "        df_tratado.fillna(0, inplace=True)\n",
    "    elif estrategia == \"remover_linhas\":\n",
    "        df_tratado.dropna(inplace=True)\n",
    "    elif estrategia == \"media\":\n",
    "        for col in df_tratado.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df_tratado[col]):\n",
    "                media = df_tratado[col].mean()\n",
    "                df_tratado[col].fillna(media, inplace=True)\n",
    "    elif estrategia == \"mediana\":\n",
    "        for col in df_tratado.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df_tratado[col]):\n",
    "                mediana = df_tratado[col].median()\n",
    "                df_tratado[col].fillna(mediana, inplace=True)\n",
    "    else:\n",
    "        print(\"Estratégia inválida. Usando 'preencher_zero' por padrão.\")\n",
    "        df_tratado.fillna(0, inplace=True)\n",
    "    return df_tratado\n",
    "\n",
    "\n",
    "def normalizar_dados(df: pd.DataFrame, metodo: str = \"zscore\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normaliza os dados numéricos de um DataFrame usando um método especificado.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame com dados numéricos.\n",
    "        metodo (str, optional): Método de normalização. Opções: 'zscore', 'minmax'.\n",
    "            Defaults to 'zscore'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados normalizados.\n",
    "    \"\"\"\n",
    "    df_normalizado = df.copy()  # Cria cópia para não alterar o original\n",
    "    for col in df_normalizado.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_normalizado[col]):\n",
    "            if metodo == \"zscore\":\n",
    "                media = df_normalizado[col].mean()\n",
    "                desvio_padrao = df_normalizado[col].std()\n",
    "                if desvio_padrao == 0:\n",
    "                    print(\n",
    "                        f\"Aviso: Desvio padrão é 0 para a coluna '{col}'. Pulando a normalização Z-score.\"\n",
    "                    )\n",
    "                    continue  # Pula para a próxima coluna\n",
    "                df_normalizado[col] = (df_normalizado[col] - media) / desvio_padrao\n",
    "            elif metodo == \"minmax\":\n",
    "                min_val = df_normalizado[col].min()\n",
    "                max_val = df_normalizado[col].max()\n",
    "                if max_val - min_val == 0:\n",
    "                    print(\n",
    "                        f\"Aviso: Amplitude é 0 para a coluna '{col}'. Pulando a normalização Min-Max.\"\n",
    "                    )\n",
    "                    continue  # Pula para a próxima coluna\n",
    "                df_normalizado[col] = (df_normalizado[col] - min_val) / (\n",
    "                    max_val - min_val\n",
    "                )\n",
    "            else:\n",
    "                print(\"Método de normalização inválido. Usando 'zscore' por padrão.\")\n",
    "                media = df_normalizado[col].mean()\n",
    "                desvio_padrao = df_normalizado[col].std()\n",
    "                if desvio_padrao == 0:\n",
    "                    print(\n",
    "                        f\"Aviso: Desvio padrão é 0 para a coluna '{col}'. Pulando a normalização Z-score.\"\n",
    "                    )\n",
    "                    continue  # Pula para a próxima coluna\n",
    "                df_normalizado[col] = (df_normalizado[col] - media) / desvio_padrao\n",
    "    return df_normalizado\n",
    "\n",
    "\n",
    "def analisar_e_salvar_dados(\n",
    "    nome_arquivo_csv: str,\n",
    "    lista_arquivos: List[str],\n",
    "    colunas_relevantes: List[str],\n",
    "    estrategia_tratamento_ausentes: str = \"preencher_zero\",\n",
    "    metodo_normalizacao: str = \"zscore\",\n",
    "    colunas_resumo: Optional[List[str]] = None,\n",
    "    num_sentencas_resumo: int = 3,\n",
    "    resumo_esperado: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Função principal que coordena o processo de análise, resumo e salvamento dos dados.\n",
    "\n",
    "    Args:\n",
    "        nome_arquivo_csv (str): Nome do arquivo CSV para salvar os resultados.\n",
    "        lista_arquivos (List[str]): Lista de arquivos a serem processados.\n",
    "        colunas_relevantes (List[str]): Colunas a serem extraídas para análise.\n",
    "        estrategia_tratamento_ausentes (str, optional): Estratégia para tratar valores ausentes.\n",
    "            Defaults to 'preencher_zero'.\n",
    "        metodo_normalizacao (str, optional): Método de normalização. Defaults to 'zscore'.\n",
    "        colunas_resumo (List[str], optional): Colunas para gerar o resumo. Se None, usa todas as colunas de texto.\n",
    "            Defaults to None.\n",
    "        num_sentencas_resumo (int, optional): Número de sentenças no resumo. Defaults to 3.\n",
    "        resumo_esperado (str, optional): Resumo de referência para teste de eficiência. Defaults to None.\n",
    "    \"\"\"\n",
    "    # Descartar arquivos inúteis\n",
    "    arquivos_uteis = descartar_arquivos_inuteis(lista_arquivos)\n",
    "    print(f\"\\nArquivos considerados úteis: {arquivos_uteis}\")\n",
    "\n",
    "    # Carregar os dados do arquivo (assumindo o primeiro arquivo útil como exemplo)\n",
    "    if not arquivos_uteis:\n",
    "        print(\"Erro: Nenhum arquivo útil encontrado para processar.\")\n",
    "        return\n",
    "\n",
    "    # Verificar se o arquivo existe antes de tentar carregá-lo\n",
    "    if not os.path.exists(arquivos_uteis[0]):\n",
    "        print(f\"Erro: O arquivo '{arquivos_uteis[0]}' não foi encontrado.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(arquivos_uteis[0])  # Carrega o primeiro arquivo útil\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extrair dados relevantes\n",
    "    df_relevante = extrair_dados_relevantes(df, colunas_relevantes)\n",
    "    if df_relevante.empty:\n",
    "        print(\"Erro: DataFrame resultante está vazio após a extração de colunas.\")\n",
    "        return\n",
    "\n",
    "    # Tratar valores ausentes\n",
    "    df_tratado = tratar_valores_ausentes(df_relevante, estrategia_tratamento_ausentes)\n",
    "\n",
    "    # Normalizar dados\n",
    "    df_normalizado = normalizar_dados(df_tratado, metodo_normalizacao)\n",
    "\n",
    "    # Analisar a utilidade das colunas\n",
    "    if colunas_resumo is None:\n",
    "        colunas_texto_para_analise = [\n",
    "            col\n",
    "            for col in df_normalizado.columns\n",
    "            if pd.api.types.is_string_dtype(df_normalizado[col])\n",
    "            or df_normalizado[col].dtype == \"object\"\n",
    "        ]\n",
    "    else:\n",
    "        colunas_texto_para_analise = colunas_resumo\n",
    "\n",
    "    analise_utilidade = identificar_dados_uteis_contabeis(\n",
    "        df_normalizado, colunas_texto=colunas_texto_para_analise\n",
    "    )\n",
    "\n",
    "    # Criar resumo\n",
    "    resumo_contabil = criar_resumos_claros(\n",
    "        df_normalizado, colunas_resumo=colunas_texto_para_analise, num_sentencas=num_sentencas_resumo\n",
    "    )\n",
    "    print(f\"\\n{resumo_contabil}\")  # Imprime o resumo na tela\n",
    "\n",
    "    # Testar a eficiência do resumo\n",
    "    if resumo_esperado:\n",
    "        eficiencia = testar_eficiencia_resumo(\n",
    "            resumo_contabil.replace(\"**Resumo Contábil:**\\n\\n\", \"\"), resumo_esperado\n",
    "        )\n",
    "        print(f\"\\nEficiência do resumo (similaridade): {eficiencia:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nResumo esperado não fornecido, pulando teste de eficiência.\")\n",
    "\n",
    "    # Salvar resultados em CSV\n",
    "    try:\n",
    "        analise_utilidade.to_csv(nome_arquivo_csv, encoding=\"utf-8\")\n",
    "        print(f\"\\nResultados salvos em: {nome_arquivo_csv}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar em CSV: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Obter o nome do arquivo de saída do usuário\n",
    "    nome_arquivo_saida = input(\"Digite o nome do arquivo CSV para salvar os resultados: \")\n",
    "    if not nome_arquivo_saida:\n",
    "        nome_arquivo_saida = \"analise_contabil_completa.csv\"  # Valor padrão se o usuário não digitar nada\n",
    "\n",
    "    lista_de_arquivos_exemplo = [\n",
    "        \"relatorio_contabil_2023.csv\",\n",
    "        \"notas_reuniao_outubro.txt\",\n",
    "        \"balanco_patrimonial_2022.xlsx\",\n",
    "        \"despesas_gerais.pdf\",\n",
    "        \"demonstrativo_resultado_trimestral.csv\",\n",
    "    ]\n",
    "    colunas_relevantes_exemplo = [\"Data\", \"Descrição\", \"Valor (R$)\", \"Conta\"]\n",
    "    resumo_esperado_exemplo = \"O relatório contábil detalha pagamentos e recebimentos, incluindo aluguel e vendas. Há registros de despesas e salários.\"\n",
    "\n",
    "    # Criar um arquivo CSV de exemplo para teste\n",
    "    data_exemplo = {\n",
    "        \"Data\": pd.to_datetime(\n",
    "            [\"2023-01-01\", \"2023-01-01\", \"2023-01-02\", \"2023-01-02\", \"2023-01-03\"]\n",
    "        ),\n",
    "        \"Descrição\": [\n",
    "            \"Pagamento de aluguel\",\n",
    "            \"Recebimento de cliente ABC\",\n",
    "            \"Compra de material de escritório\",\n",
    "            \"Venda de mercadoria XYZ\",\n",
    "            \"Salário de funcionários\",\n",
    "        ],\n",
    "        \"Valor (R$)\": [1200.50, 5000.00, 350.75, 2800.00, 6000.00],\n",
    "        \"Conta\": [\n",
    "            \"Despesas com aluguel\",\n",
    "            \"Receita de vendas\",\n",
    "            \"Despesas administrativas\",\n",
    "            \"Receita de vendas\",\n",
    "            \"Folha de pagamento\",\n",
    "        ],\n",
    "        \"Observação\": [\n",
    "            \"Referente ao mês de dezembro\",\n",
    "            \"\",\n",
    "            \"Para uso interno\",\n",
    "            \"NF emitida\",\n",
    "            \"\",\n",
    "        ],\n",
    "        \"ID\": [1, 2, 3, 4, 5],\n",
    "        \"Moeda\": [\"R$\", \"R$\", \"R$\", \"R$\", \"R$\"],\n",
    "    }\n",
    "    df_exemplo = pd.DataFrame(data_exemplo)\n",
    "    df_exemplo.to_csv(\"relatorio_contabil_2023.csv\", index=False)  # Salva o arquivo de exemplo\n",
    "\n",
    "    # Chamar a função principal\n",
    "    analisar_e_salvar_dados(\n",
    "        nome_arquivo_csv=nome_arquivo_saida,\n",
    "        lista_arquivos=lista_de_arquivos_exemplo,\n",
    "        colunas_relevantes=colunas_relevantes_exemplo,\n",
    "        estrategia_tratamento_ausentes=\"media\",\n",
    "        metodo_normalizacao=\"minmax\",\n",
    "        colunas_resumo=[\"Descrição\", \"Conta\", \"Observação\"],\n",
    "        num_sentencas_resumo=2,\n",
    "        resumo_esperado=resumo_esperado_exemplo,\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
