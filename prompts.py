import os
import joblib
import re
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path

# --- Configura√ß√µes Iniciais ---
# Configurar Pandas para n√£o truncar a sa√≠da de .to_string()
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 160)
pd.set_option('display.max_colwidth', 50)

# Carregar as chaves da API via .env
env_path = Path(__file__).resolve().parent / '.env'
load_dotenv(dotenv_path=env_path)
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("OPENAI_API_KEY n√£o encontrada no arquivo .env ou nas vari√°veis de ambiente.")

# Inicializar o cliente da OpenAI
client = OpenAI(api_key=openai_api_key)

# Modelo OpenAI Fixo para os testes
MODELO_ID_FIXO = "gpt-4o-mini"
NOME_SUBPASTA_MODELO = "gpt4mini" # Nome da subpasta para os resultados

# Diret√≥rios Base
base_dir = Path(__file__).resolve().parent
# Ajuste conforme a estrutura do seu projeto. 'util/data' parece ser o caminho correto para .z
# Se os arquivos CSV estiverem em outro local, ajuste o caminho conforme necess√°rio.
# Certifique-se de que o diret√≥rio 'util/data' cont√©m os arquivos .z necess√°rios
# Para este c√≥digo, estou focando na leitura de .z como a principal fonte de dados cont√°beis estruturados.
data_dir_z = base_dir.parent.parent / 'util' / 'data'
relatorio_dir_base = base_dir / 'task18_resultados' # Pasta principal de sa√≠da

# --- Fun√ß√µes de Leitura de Dados ---

def ler_arquivo_csv(caminho_arquivo: Path) -> str | None:
    """
    L√™ o conte√∫do de um arquivo CSV e retorna como uma string.
    Retorna None em caso de erro ou arquivo n√£o encontrado.
    """
    try:
        with open(caminho_arquivo, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"Erro: Arquivo CSV n√£o encontrado: '{caminho_arquivo}'")
        return None
    except Exception as e:
        print(f"Erro ao ler arquivo CSV: '{caminho_arquivo}'. Erro: {e}")
        return None

def carregar_e_processar_dados_para_llm(data_dir: Path) -> str:
    """
    Carrega arquivos .z (DataFrames) de um diret√≥rio, aplica uma estrat√©gia de redu√ß√£o
    e retorna o conte√∫do como uma string formatada para inclus√£o no prompt do LLM.
    """
    arquivos_z = list(data_dir.glob('*.z'))
    dados = {}
    if not arquivos_z:
        print(f"‚ö†Ô∏è Nenhum arquivo .z encontrado em {data_dir}. O conte√∫do dos dados estar√° vazio.")
    else:
        print(f"Arquivos .z encontrados em {data_dir}:")
        for arquivo in arquivos_z:
            print(f"  - {arquivo.name}")
            try:
                dados[arquivo.name] = joblib.load(arquivo)
            except Exception as e:
                print(f"  ‚ùå Erro ao carregar {arquivo.name}: {e}")

    conteudo_dados = "### DADOS A SEREM ANALISADOS ###\n\n"
    print("\nüîÑ Processando DataFrames para inclus√£o no prompt (estrat√©gia de redu√ß√£o agressiva)...")

    ROWS_SMALL_DF = 75
    ROWS_MEDIUM_DF_HEADTAIL = 15
    ROWS_LARGE_DF_HEADTAIL = 10
    ROWS_VERY_LARGE_DF_HEADTAIL = 5

    for nome, df_content in dados.items():
        df_shape = df_content.shape if hasattr(df_content, 'shape') else (0,0)
        conteudo_dados += f"### Arquivo: {nome} (Shape: {df_shape}) ###\n"

        if not hasattr(df_content, 'to_string') or not hasattr(df_content, 'describe'):
            print(f"  üìÑ Conte√∫do n√£o √© DataFrame ou n√£o tem os m√©todos esperados (convertendo como string gen√©rica): {nome}")
            conteudo_dados += str(df_content)
            conteudo_dados += "\n\n"
            continue

        num_rows = df_shape[0]

        if num_rows <= ROWS_SMALL_DF:
            print(f"  üìÑ Incluindo DataFrame completo (<= {ROWS_SMALL_DF} linhas): {nome}")
            conteudo_dados += df_content.to_string()
        else:
            head_n, tail_n = ROWS_LARGE_DF_HEADTAIL, ROWS_LARGE_DF_HEADTAIL
            if num_rows <= 200:
                head_n, tail_n = ROWS_MEDIUM_DF_HEADTAIL, ROWS_MEDIUM_DF_HEADTAIL
            elif num_rows > 3000:
                head_n, tail_n = ROWS_VERY_LARGE_DF_HEADTAIL, ROWS_VERY_LARGE_DF_HEADTAIL

            print(f"  üìÑ Incluindo head({head_n}), tail({tail_n}) e describe() para: {nome}")
            conteudo_dados += f"--- IN√çCIO DAS PRIMEIRAS {head_n} LINHAS DE {nome} ---\n"
            conteudo_dados += df_content.head(head_n).to_string()
            conteudo_dados += f"\n--- FIM DAS PRIMEIRAS {head_n} LINHAS DE {nome} ---\n\n"

            conteudo_dados += f"--- IN√çCIO DAS √öLTIMAS {tail_n} LINHAS DE {nome} ---\n"
            conteudo_dados += df_content.tail(tail_n).to_string()
            conteudo_dados += f"\n--- FIM DAS √öLTIMAS {tail_n} LINHAS DE {nome} ---\n\n"

            try:
                conteudo_dados += f"--- RESUMO ESTAT√çSTICO (DESCRIBE) DE {nome} ---\n"
                conteudo_dados += df_content.describe(include='all').to_string()
                conteudo_dados += f"\n--- FIM DO RESUMO ESTAT√çSTICO DE {nome} ---\n"
            except Exception as e:
                print(f"    ‚ö†Ô∏è N√£o foi poss√≠vel gerar describe() para {nome}: {e}")
                conteudo_dados += f"--- RESUMO ESTAT√çSTICO (DESCRIBE) DE {nome} INDISPON√çVEL ---\n"

        conteudo_dados += "\n\n"

    tamanho_estimado_conteudo_dados_bytes = len(conteudo_dados.encode('utf-8'))
    tamanho_estimado_conteudo_dados_kb = tamanho_estimado_conteudo_dados_bytes / 1024
    tokens_estimados_dados = tamanho_estimado_conteudo_dados_bytes / 4

    print(f"‚ÑπÔ∏è Tamanho estimado do 'conteudo_dados' (estrat√©gia agressiva): {tamanho_estimado_conteudo_dados_kb:.2f} KB")
    print(f"‚ÑπÔ∏è Tokens estimados para 'conteudo_dados' (aprox.): {tokens_estimados_dados:.0f} tokens")
    print("  GPT-4o-mini tem um grande contexto (128k tokens), mas √© bom monitorar o uso de tokens para custos e performance.")

    return conteudo_dados


# --- Prompts Comparativos ---
prompts_comparativos = {
    "prompt1": """Com base nos dados fornecidos, elabore um √∫nico resumo conciso contendo quatro se√ß√µes:

1. Fluxo de Caixa Operacional
2. Desempenho de Vendas por Categoria
3. Liquidez da Empresa
4. Principais Gastos ‚Äì maiores centros de custo e varia√ß√£o relevante.

Use linguagem direta, sem jarg√µes desnecess√°rios, focada em decis√µes r√°pidas.""",
    "prompt2": """Voc√™ √© um Analista Financeiro S√™nior encarregado de preparar um briefing executivo para a diretoria. Com base nos dados financeiros fornecidos (incluindo categorias, contas a pagar, contas a receber, movimento financeiro, naturezas financeiras, produtos e vendas):
1. Sum√°rio Executivo: Apresente um panorama geral da sa√∫de financeira da empresa, considerando a intera√ß√£o entre vendas, custos (impl√≠citos nas contas a pagar e naturezas financeiras) e o fluxo de caixa (movimento financeiro).
2. Indicadores Chave (KPIs): Destaque os 3-5 KPIs mais relevantes. Considere:
    * Rentabilidade por produto ou categoria (cruzando df_vendas, df_produtos, df_categorias).
    * Ciclo de convers√£o de caixa (analisando prazos de df_contas_a_receber e df_contas_a_pagar).
    * N√≠veis de inadimpl√™ncia (de df_contas_a_receber).
    * Concentra√ß√£o de vendas (em produtos ou categorias).
3. Principais Riscos e Alertas: Identifique de 2 a 3 riscos financeiros ou operacionais cr√≠ticos. Analise:
    * Riscos de liquidez com base no movimento financeiro e nas obriga√ß√µes de contas a pagar versus receb√≠veis.
    * Depend√™ncia excessiva de poucos produtos ou categorias (df_produtos, df_categorias, df_vendas).
    * Aumento de despesas espec√≠ficas (df_naturezas_financeiras, df_contas_a_pagar).
4. Recomenda√ß√µes Estrat√©gicas: Sugira de 1 a 2 a√ß√µes priorit√°rias para mitigar riscos ou capitalizar oportunidades, referenciando quais √°reas (vendas, gest√£o de pagamentos/recebimentos, etc.) seriam impactadas.
Utilize bullet points para clareza e uma linguagem direta e focada na tomada de decis√£o."""
}

# --- Fun√ß√µes de Gera√ß√£o de Resumo ---

def enviar_prompt_para_llm(user_prompt_content: str, model_id: str = MODELO_ID_FIXO) -> str:
    """
    Envia um prompt para o Modelo de Linguagem Grande (LLM) da OpenAI e retorna a resposta.
    """
    system_message = "Voc√™ √© um especialista cont√°bil e financeiro altamente qualificado, capaz de adaptar seu estilo de comunica√ß√£o e an√°lise conforme solicitado."
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_prompt_content}
    ]

    params = {
        "model": model_id,
        "messages": messages,
        "max_tokens": 4096, # Um valor alto para garantir espa√ßo para a resposta
        "temperature": 0.3,
        "top_p": 0.9
    }

    try:
        chat_completion = client.chat.completions.create(**params)
        return chat_completion.choices[0].message.content.strip()
    except Exception as e:
        error_details_str = str(e)
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_data = e.response.json()
                if 'error' in error_data:
                    error_details_str += f" (API Error: {error_data['error']})"
            except:
                pass
        elif hasattr(e, 'body') and e.body is not None:
            error_details_str += f" (Error Body: {e.body})"

        print(f"  ‚ùå Erro ao chamar a API da OpenAI: {e}")
        print(f"    Detalhes do erro: {error_details_str}")
        if "context_length_exceeded" in error_details_str.lower() or \
           "prompt is too long" in error_details_str.lower() or \
           "tokens" in error_details_str.lower():
            print("  ‚ÄºÔ∏è ERRO: O PROMPT PROVAVELMENTE EXCEDEU O TAMANHO M√ÅXIMO DE CONTEXTO/REQUISI√á√ÉO DO MODELO! ‚ÄºÔ∏è")
            print("  Considere reduzir MAIS AINDA a quantidade de dados enviados ou usar uma estrat√©gia de sumariza√ß√£o mais agressiva.")
        return "Erro ao gerar resumo."

def gerar_resumo_contabil_hibrido(dados_processados: str, prompt_base_tipo: str, prompt_refinador_tipo: str) -> str:
    """
    Gera um resumo cont√°bil usando a abordagem h√≠brida:
    1. Aplica o prompt base para extra√ß√£o prim√°ria.
    2. Alimenta o resultado ao prompt refinador para detalhes estrat√©gicos.
    """
    # 1. Aplica√ß√£o do Prompt Base (Prompt 1 para extra√ß√£o e padroniza√ß√£o)
    prompt_1_texto = prompts_comparativos[prompt_base_tipo]
    prompt_1_final = f"{prompt_1_texto}\n\nDados:\n{dados_processados}"
    print(f"\n--- Gerando Resumo Base com '{prompt_base_tipo}' ---")
    resumo_base = enviar_prompt_para_llm(prompt_1_final)
    print(f"\nResumo Base Gerado:\n{resumo_base[:500]}...") # Exibe uma parte do resumo base

    if "Erro ao gerar resumo." in resumo_base:
        return "Erro na gera√ß√£o do resumo base. Abortando processo h√≠brido."

    # 2. Aplica√ß√£o do Prompt Refinador (Prompt 2 para enriquecimento estrat√©gico)
    prompt_2_texto = prompts_comparativos[prompt_refinador_tipo]
    prompt_2_final = f"{prompt_2_texto}\n\nAnalise o seguinte resumo inicial e os dados originais para enriquecer a resposta:\n\nResumo Inicial:\n{resumo_base}\n\nDados Originais:\n{dados_processados}"
    print(f"\n--- Refinando Resumo com '{prompt_refinador_tipo}' ---")
    resumo_final_hibrido = enviar_prompt_para_llm(prompt_2_final)
    print(f"\nResumo Refinado Gerado:\n{resumo_final_hibrido[:500]}...") # Exibe uma parte do resumo refinado

    return resumo_final_hibrido

# --- Fun√ß√£o Principal ---

def main():
    if not openai_api_key:
        print("Erro: A chave da API do OpenAI n√£o foi configurada. Certifique-se de ter um arquivo .env com OPENAI_API_KEY.")
        return

    # Carrega e processa os dados dos arquivos .z
    conteudo_dados_llm = carregar_e_processar_dados_para_llm(data_dir_z)

    if not conteudo_dados_llm.strip():
        print("Nenhum conte√∫do de dados foi carregado ou processado. Encerrando.")
        return

    print("\n--- Escolha a Abordagem para o Resumo Cont√°bil ---")
    print("1: Prompt 1 (An√°lise Setorial Concisa) - Ideal para relat√≥rios operacionais di√°rios.")
    print("2: Prompt 2 (Briefing Executivo Estrat√©gico) - Ideal para an√°lises mais profundas e estrat√©gicas.")
    print("3: Abordagem H√≠brida (Prompt 1 como base, Prompt 2 como refinador) - Recomendado para resultados otimizados.")
    print("0: Sair")

    while True:
        escolha = input("Digite o n√∫mero da sua escolha: ")

        resumo_gerado = None
        nome_tipo_resumo = ""

        if escolha == '1':
            nome_tipo_resumo = "Prompt1_Conciso"
            resumo_gerado = enviar_prompt_para_llm(f"{prompts_comparativos['prompt1']}\n\nDados:\n{conteudo_dados_llm}")
        elif escolha == '2':
            nome_tipo_resumo = "Prompt2_Estrategico"
            resumo_gerado = enviar_prompt_para_llm(f"{prompts_comparativos['prompt2']}\n\nDados:\n{conteudo_dados_llm}")
        elif escolha == '3':
            nome_tipo_resumo = "Hibrido_P1_P2"
            resumo_gerado = gerar_resumo_contabil_hibrido(conteudo_dados_llm, "prompt1", "prompt2")
        elif escolha == '0':
            print("Saindo do programa.")
            return
        else:
            print("Op√ß√£o inv√°lida. Por favor, digite 1, 2, 3 ou 0.")
            continue

        if resumo_gerado and "Erro ao gerar resumo." not in resumo_gerado:
            print("\n--- Resumo Gerado ---")
            print(resumo_gerado)

            # Salvar o resumo
            relatorio_dir_modelo_especifico = relatorio_dir_base / NOME_SUBPASTA_MODELO
            relatorio_dir_modelo_especifico.mkdir(parents=True, exist_ok=True)
            nome_arquivo_resumo = relatorio_dir_modelo_especifico / f"{nome_tipo_resumo}_resultado.txt"
            with open(nome_arquivo_resumo, "w", encoding="utf-8") as arquivo:
                arquivo.write(f"Modelo Utilizado: {MODELO_ID_FIXO}\n\n")
                arquivo.write(f"--- {nome_tipo_resumo.upper()} ---\n")
                if escolha == '1':
                    arquivo.write(f"Instru√ß√£o do Prompt:\n{prompts_comparativos['prompt1']}\n\n")
                elif escolha == '2':
                    arquivo.write(f"Instru√ß√£o do Prompt:\n{prompts_comparativos['prompt2']}\n\n")
                elif escolha == '3':
                    arquivo.write(f"Instru√ß√£o do Prompt Base (P1):\n{prompts_comparativos['prompt1']}\n\n")
                    arquivo.write(f"Instru√ß√£o do Prompt Refinador (P2):\n{prompts_comparativos['prompt2']}\n\n")
                arquivo.write("--- RESPOSTA DO MODELO ---\n")
                arquivo.write(resumo_gerado)
            print(f"\nO resumo foi salvo em '{nome_arquivo_resumo}'.")
        else:
            print(f"\nN√£o foi poss√≠vel gerar o resumo para a op√ß√£o {escolha}.")

        # Perguntar se o usu√°rio quer gerar outro resumo
        continuar = input("\nGerar outro resumo? (s/n): ").lower()
        if continuar != 's':
            print("Encerrando o programa.")
            break

if __name__ == "__main__":
    main()